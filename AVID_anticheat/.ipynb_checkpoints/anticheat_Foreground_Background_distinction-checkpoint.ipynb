{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA, FactorAnalysis,KernelPCA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from anticheat_common import k_means,k_means2,k_means_kernal_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "#样例数据（）1138f910700444eeb5cef2d4137cfe05,2017-01-18 09:39:57,600020,_CI,4\n",
    "def loadDataSet(file):\n",
    "    \"\"\"\n",
    "    保存成dic形式，dic中的元素为dic\n",
    "    \"\"\"\n",
    "    dataDic = {}\n",
    "    fr = open(file)\n",
    "    for line in fr.readlines():\n",
    "        dic = {}\n",
    "        lineArr = line.strip().split(',')\n",
    "        idKey = lineArr[0]\n",
    "        typeKey = lineArr[3]\n",
    "        \n",
    "        if dataDic.has_key(idKey):\n",
    "            dic = dataDic[idKey]\n",
    "            if dic.has_key(typeKey):\n",
    "                value = dic[typeKey]\n",
    "                dic[typeKey] = value + 1\n",
    "            else:\n",
    "                dic[typeKey] = 1\n",
    "        else:\n",
    "            dic[typeKey] = 1\n",
    "        \n",
    "        dataDic[idKey]=dic\n",
    "    fr.close()\n",
    "    return dataDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(dic):\n",
    "    \"\"\"\n",
    "    在用户的行为中增加前台行为和后台行为的统计。\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for key in dic:\n",
    "        value = dic[key]\n",
    "        _All = 0\n",
    "        All = 0\n",
    "        for miniKey in value:\n",
    "            if miniKey[0] == '_':\n",
    "                _All = _All + value[miniKey]\n",
    "            else:\n",
    "                All = All + value[miniKey]\n",
    "        value['_ALL'] = _All\n",
    "        value['ALL'] = All\n",
    "        data[key] = value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeDataMat(dic):\n",
    "    \"\"\"\n",
    "    把用户id和数据dic分开\n",
    "    \"\"\"\n",
    "    idMat = []\n",
    "    dataMat = []\n",
    "    for key in dic:\n",
    "        dataMat.append(dic[key])\n",
    "        idMat.append(key)\n",
    "    return idMat, dataMat\n",
    "\n",
    "def makeVec(mat):\n",
    "    \"\"\"\n",
    "    把用户行为字典变为向量\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    dataVec = vec.fit_transform(mat).toarray()\n",
    "    print dataVec.shape\n",
    "    print dataVec[0]\n",
    "    return dataVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136\n",
      "(4136, 8)\n",
      "[  5.  11.   1.   4.   1.   1.   1.   0.]\n"
     ]
    }
   ],
   "source": [
    "filename = \"/Users/holazhai/Documents/data/s3data/20170119_600025.log\"\n",
    "dataDic = loadDataSet(filename)\n",
    "print len(dataDic)\n",
    "\n",
    "preData = preprocess(dataDic)\n",
    "\n",
    "idMat, dataMat = makeDataMat(preData)\n",
    "#print dataMat\n",
    "dataVec = makeVec(dataMat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.18628189121 102.092567971\n",
      "-20.8830711957 416.291720936\n",
      "[[  -5.18628189  -20.8830712 ]\n",
      " [  -5.16628189  -20.8830712 ]\n",
      " [  -5.14628189  -20.8830712 ]\n",
      " ..., \n",
      " [ 102.03371811  416.2769288 ]\n",
      " [ 102.05371811  416.2769288 ]\n",
      " [ 102.07371811  416.2769288 ]]\n"
     ]
    }
   ],
   "source": [
    "k_means(dataVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
