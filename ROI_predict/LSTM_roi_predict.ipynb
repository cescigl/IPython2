{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "timeLong = 30\n",
    "step = 20\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logPathSortUniq = '/Users/holazhai/Documents/workspace/readshift/result_uniq_sort_ha_holaverse_int.log'\n",
    "colnameSortUniq = ['created_day', 'pdtid', 'pid','u','dt']\n",
    "dfSortUniq = pd.read_table(logPathSortUniq,sep='\\t',names=colnameSortUniq)\n",
    "dfSortUniq['key'] = zip(dfSortUniq['created_day'],dfSortUniq['pdtid'],dfSortUniq['pid'],dfSortUniq['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfDic(dfSortUniq):\n",
    "    dfDic = {}\n",
    "    for index, row in dfSortUniq.iterrows():\n",
    "        key = row['key']\n",
    "        value = row['dt']\n",
    "        #print key,value\n",
    "        if dfDic.has_key(key):\n",
    "            dfDic[key].append(value)\n",
    "        else:\n",
    "            dfDic[key]=[value]\n",
    "    return dfDic\n",
    "dfDic=getDfDic(dfSortUniq)\n",
    "\n",
    "import datetime\n",
    "def plusDay(strTime):\n",
    "    time1 = datetime.datetime.strptime(strTime,'%Y-%m-%d')\n",
    "    next_dat = time1 + datetime.timedelta(hours = 24)\n",
    "    next_str = datetime.datetime.strftime(next_dat,'%Y-%m-%d')\n",
    "    return str(next_str)\n",
    "\n",
    "def diffDay(day1,day2):\n",
    "    d1=datetime.datetime.strptime(day1,'%Y-%m-%d')\n",
    "    d2=datetime.datetime.strptime(day2,'%Y-%m-%d')\n",
    "    return (d1-d2).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16724\n",
      "16724\n"
     ]
    }
   ],
   "source": [
    "def getDfListKeyAndValue(dfDic):\n",
    "    dfListKey = []\n",
    "    dfListValue = []\n",
    "    for key in dfDic.keys():\n",
    "        l = dfDic[key]\n",
    "        ltempKey = []\n",
    "        ltempValue = []\n",
    "        times = key[0]\n",
    "    \n",
    "        if times in l:\n",
    "            l.remove(times)\n",
    "        \n",
    "        if len(l)==0:\n",
    "            pass;\n",
    "        else:\n",
    "            #print l,times,plusDay(times),diffDay(plusDay(times),times)\n",
    "            ltempKey.append(key)\n",
    "            for i in range(len(l)):\n",
    "                diff = diffDay(l[i],times)\n",
    "                times = l[i]\n",
    "                for i in range(diff-1):\n",
    "                    ltempValue.append(0)\n",
    "                ltempValue.append(1)\n",
    "            if len(ltempValue)<timeLong:\n",
    "                for i in range(timeLong-len(ltempValue)):\n",
    "                    ltempValue.append(0)\n",
    "            #print ltempKey,ltempValue\n",
    "            dfListKey.append(ltempKey)\n",
    "            dfListValue.append(ltempValue)\n",
    "            \n",
    "    return dfListKey,dfListValue\n",
    "dfListKey,dfListValue = getDfListKeyAndValue(dfDic)\n",
    "            \n",
    "print len(dfListValue)\n",
    "print len(dfListKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfArrayKey=[]\n",
    "dfArrayValue =[]\n",
    "length = len(dfListKey)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(timeLong-step-1):\n",
    "        #取五分之一的负样本,为了样本平衡\n",
    "        if dfListValue[i][j+step] == 0:\n",
    "            if np.random.random() >0.80:\n",
    "                dfArrayValue.append(dfListValue[i][j:j+step+1])\n",
    "                dfArrayKey.append(dfListKey[i])\n",
    "        else:\n",
    "            dfArrayValue.append(dfListValue[i][j:j+step+1])\n",
    "            dfArrayKey.append(dfListKey[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49749, 1, 20)\n",
      "(49749,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(dfArrayValue)[:,0:step]\n",
    "y_train = np.array(dfArrayValue)[:,step] \n",
    "x_train = x_train.reshape(x_train.shape[0],1,step)\n",
    "print x_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#train NN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32,input_shape=(1,step)))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "49749/49749 [==============================] - 15s - loss: 0.3998 - acc: 0.8474    \n",
      "Epoch 2/5\n",
      "49749/49749 [==============================] - 16s - loss: 0.3278 - acc: 0.8727    \n",
      "Epoch 3/5\n",
      "49749/49749 [==============================] - 16s - loss: 0.3060 - acc: 0.8895    \n",
      "Epoch 4/5\n",
      "49749/49749 [==============================] - 17s - loss: 0.2993 - acc: 0.8944    \n",
      "Epoch 5/5\n",
      "49749/49749 [==============================] - 16s - loss: 0.3167 - acc: 0.8844    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125092e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=64, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24647\n",
      "49749\n"
     ]
    }
   ],
   "source": [
    "#存在问题，正负样本数目不一致\n",
    "y_train\n",
    "a = np.array(filter(lambda x: x > 0, y_train))\n",
    "print len(a)\n",
    "print len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44749, 1, 20)\n",
      "(5000, 1, 20)\n",
      "(44749,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "x1=x_train[0:-5000][:][:]\n",
    "print x1.shape\n",
    "x2=x_train[-5000:][:][:]\n",
    "print x2.shape\n",
    "y1=y_train[0:-5000][:]\n",
    "print y1.shape\n",
    "y2=y_train[-5000:][:]\n",
    "print y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(64,input_shape=(1,step),return_sequences=True))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(32,activation='relu'))\n",
    "model2.add(Dense(1,activation='relu'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 44749 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "44749/44749 [==============================] - 54s - loss: 0.4203 - acc: 0.8423 - val_loss: 0.3402 - val_acc: 0.8894\n",
      "Epoch 2/5\n",
      "44749/44749 [==============================] - 50s - loss: 0.5438 - acc: 0.8430 - val_loss: 0.2945 - val_acc: 0.8912\n",
      "Epoch 3/5\n",
      "44749/44749 [==============================] - 49s - loss: 0.2858 - acc: 0.8922 - val_loss: 0.2774 - val_acc: 0.8996\n",
      "Epoch 4/5\n",
      "44749/44749 [==============================] - 46s - loss: 0.3517 - acc: 0.8671 - val_loss: 0.5996 - val_acc: 0.5088\n",
      "Epoch 5/5\n",
      "44749/44749 [==============================] - 48s - loss: 0.3256 - acc: 0.8642 - val_loss: 0.2800 - val_acc: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129df4d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model2.fit(x1, y1, batch_size=32, nb_epoch=5,shuffle=True,validation_data=(x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-15a778f39f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my2_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtestScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtestScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y2_p=model2.predict(x2)\n",
    "testScore = math.sqrt(mean_squared_error(y2, y2_p))\n",
    "print testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44749, 20, 1)\n",
      "(5000, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "#LSTM \n",
    "xx1=x1.reshape(x1.shape[0],x1.shape[2],x1.shape[1])\n",
    "print xx1.shape\n",
    "yy1=y1\n",
    "xx2=x2.reshape(x2.shape[0],x2.shape[2],x2.shape[1])\n",
    "yy2=y2\n",
    "print xx2.shape\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(64,input_shape=(step,1),return_sequences=True))\n",
    "model3.add(LSTM(64))\n",
    "model3.add(Dense(32,activation='tanh'))\n",
    "model3.add(Dense(1,activation='tanh'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20, 64)            16896     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 52,033.0\n",
      "Trainable params: 52,033\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44749 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "44749/44749 [==============================] - 99s - loss: 0.3065 - acc: 0.8861 - val_loss: 0.3545 - val_acc: 0.8996\n",
      "Epoch 2/20\n",
      "44749/44749 [==============================] - 97s - loss: 0.2973 - acc: 0.8996 - val_loss: 0.2721 - val_acc: 0.9034\n",
      "Epoch 3/20\n",
      "44749/44749 [==============================] - 98s - loss: 0.2730 - acc: 0.9017 - val_loss: 0.2709 - val_acc: 0.9034\n",
      "Epoch 4/20\n",
      "44749/44749 [==============================] - 99s - loss: 0.2723 - acc: 0.9016 - val_loss: 0.2698 - val_acc: 0.9036\n",
      "Epoch 5/20\n",
      "44749/44749 [==============================] - 102s - loss: 0.2800 - acc: 0.9006 - val_loss: 0.2710 - val_acc: 0.9044\n",
      "Epoch 6/20\n",
      "44749/44749 [==============================] - 99s - loss: 0.2704 - acc: 0.9025 - val_loss: 0.2689 - val_acc: 0.9026\n",
      "Epoch 7/20\n",
      "44749/44749 [==============================] - 102s - loss: 0.2690 - acc: 0.9026 - val_loss: 0.2690 - val_acc: 0.9010\n",
      "Epoch 8/20\n",
      "44749/44749 [==============================] - 98s - loss: 0.2958 - acc: 0.8991 - val_loss: 0.2751 - val_acc: 0.9022\n",
      "Epoch 9/20\n",
      "44749/44749 [==============================] - 98s - loss: 0.2846 - acc: 0.9017 - val_loss: 0.2689 - val_acc: 0.9018\n",
      "Epoch 10/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2721 - acc: 0.9030 - val_loss: 0.2730 - val_acc: 0.9010\n",
      "Epoch 11/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2686 - acc: 0.9030 - val_loss: 0.2691 - val_acc: 0.9010\n",
      "Epoch 12/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2876 - acc: 0.9013 - val_loss: 0.2949 - val_acc: 0.9030\n",
      "Epoch 13/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2703 - acc: 0.9031 - val_loss: 0.2674 - val_acc: 0.9010\n",
      "Epoch 14/20\n",
      "44749/44749 [==============================] - 97s - loss: 0.2692 - acc: 0.9029 - val_loss: 0.2685 - val_acc: 0.9010\n",
      "Epoch 15/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2667 - acc: 0.9036 - val_loss: 0.2693 - val_acc: 0.9010\n",
      "Epoch 16/20\n",
      "44749/44749 [==============================] - 96s - loss: 0.2672 - acc: 0.9033 - val_loss: 0.2690 - val_acc: 0.9012\n",
      "Epoch 17/20\n",
      "44749/44749 [==============================] - 97s - loss: 0.2670 - acc: 0.9039 - val_loss: 0.2687 - val_acc: 0.9006\n",
      "Epoch 18/20\n",
      "44749/44749 [==============================] - 97s - loss: 0.2669 - acc: 0.9036 - val_loss: 0.2680 - val_acc: 0.9006\n",
      "Epoch 19/20\n",
      "44749/44749 [==============================] - 97s - loss: 0.2665 - acc: 0.9032 - val_loss: 0.2687 - val_acc: 0.8990\n",
      "Epoch 20/20\n",
      "44749/44749 [==============================] - 95s - loss: 0.2665 - acc: 0.9033 - val_loss: 0.2686 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a5ad950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model3.fit(xx1, yy1, batch_size=64, nb_epoch=20,shuffle=True,validation_data=(xx2, yy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49749\n",
      "<type 'list'>\n",
      "49749\n",
      "<type 'list'>\n",
      "<type 'list'>\n",
      "('2016-07-26', 600004, 'ha_holaverse_int', 'febb010723f0427794e41300f449380b')\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "16724\n"
     ]
    }
   ],
   "source": [
    "#LSTM With Memory Between Batches\n",
    "#http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "#验证留存率计算结果\n",
    "#2016-07-24600004ha_holaverse_int 28742\n",
    "print len(dfArrayKey)\n",
    "print type(dfArrayKey)\n",
    "print len(dfArrayValue)\n",
    "print type(dfArrayValue)\n",
    "#选择测试数据 2016-06-06#600001#Organic_up\n",
    "\n",
    "print type(dfListKey)\n",
    "print dfListKey[0][0]\n",
    "print dfListValue[0]\n",
    "print len(dfListValue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfArrayKeyTest=[]\n",
    "dfArrayValueTest =[]\n",
    "length = len(dfListKey)\n",
    "for i in range(length):\n",
    "    keyTimes = dfListKey[i][0][0]\n",
    "    proid = dfListKey[i][0][1]\n",
    "    pid = dfListKey[i][0][2]\n",
    "    if keyTimes=='2016-07-25' and proid==600004 and pid=='ha_holaverse_int':\n",
    "        dfArrayValueTest.append(dfListValue[i][0:step+1])\n",
    "        dfArrayKeyTest.append(dfListKey[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 20)\n",
      "(1458, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "testX = np.array(dfArrayValueTest)[:,0:step]\n",
    "testY = np.array(dfArrayValueTest)[:,step] \n",
    "print testX.shape\n",
    "testX = testX.reshape(testX.shape[0],step,1)\n",
    "print testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "predictTestX = model3.predict(testX)\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "predictTestX = model.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a6ac378852d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictTestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictTestX\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "predictTestX = model2.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#测试过程\n",
    "logPathSortUniq20160801 = '/Users/holazhai/Documents/workspace/readshift/result_uniq_sort_20160801.log'\n",
    "colnameSortUniq20160801 = ['created_day', 'pdtid', 'pid','u','dt']\n",
    "dfSortUniq20160801 = pd.read_table(logPathSortUniq20160801,sep='\\t',names=colnameSortUniq20160801)\n",
    "\n",
    "dfSortUniq20160801['key'] = zip(dfSortUniq20160801['created_day'],dfSortUniq20160801['pdtid'],dfSortUniq20160801['pid'],dfSortUniq20160801['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001\n",
      "9001\n"
     ]
    }
   ],
   "source": [
    "dfDic20160801=getDfDic(dfSortUniq20160801)\n",
    "dfListKey20160801,dfListValue20160801 = getDfListKeyAndValue(dfDic20160801)\n",
    "print len(dfListKey20160801)\n",
    "print len(dfListValue20160801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9001\n"
     ]
    }
   ],
   "source": [
    "dfArrayKeyTest20160801=[]\n",
    "dfArrayValueTest20160801 =[]\n",
    "length = len(dfListKey20160801)\n",
    "print length\n",
    "for i in range(length):\n",
    "    keyTimes = dfListKey20160801[i][0][0]\n",
    "    proid = dfListKey20160801[i][0][1]\n",
    "    pid = dfListKey20160801[i][0][2]\n",
    "    if keyTimes=='2016-08-04' and proid==600004 and pid=='ha_holaverse_int':\n",
    "        #print dfListValue20160801[i][0:21]\n",
    "        dfArrayValueTest20160801.append(dfListValue20160801[i][0:21])\n",
    "        dfArrayKeyTest20160801.append(dfListKey20160801[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 20)\n",
      "(665, 20, 1)\n",
      "model3:\n",
      "152\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "testX = np.array(dfArrayValueTest20160801)[:,0:step]\n",
    "testY = np.array(dfArrayValueTest20160801)[:,step] \n",
    "print testX.shape\n",
    "testX = testX.reshape(testX.shape[0],step,1)\n",
    "print testX.shape\n",
    "predictTestX = model3.predict(testX)\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model3:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictTestX = model.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)\n",
    "predictTestX = model2.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model2:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
