{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "from keras.layers.convolutional import (Convolution3D, MaxPooling3D,ZeroPadding3D,Convolution2D,MaxPooling2D)\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2, activity_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = np.empty((2587,9,3,64,48),dtype=\"float32\")\n",
    "    label = np.empty((2587,),dtype=\"uint8\")\n",
    "    imgPath='/Users/baidu/Documents/workspace/Action_recognition_scripts_UCF101/data/tmp_frames/train/'\n",
    "    f = open('/Users/baidu/Documents/workspace/Action_recognition_scripts_UCF101/data/ucfTrainTestlist/trainlist05.txt')\n",
    "    vids = f.readlines()\n",
    "    vids = [video.rstrip() for video in vids]\n",
    "    \n",
    "    for i in range(len(vids)):\n",
    "        keypath=vids[i].split('/')[1].split('.')[0]\n",
    "        value=vids[i].split(' ')[1]\n",
    "        label[i]=value\n",
    "        #print keypath\n",
    "        #print value\n",
    "        for j in range(1,10):\n",
    "            path=imgPath+keypath+'_0'+str(j)+'.jpeg'\n",
    "            if os.path.exists(path):\n",
    "                img=Image.open(imgPath+keypath+'_0'+str(j)+'.jpeg')\n",
    "                img=img.resize((64,48))\n",
    "                #print imgPath+keypath+'_0'+str(j)+'.jpeg'\n",
    "                arr = np.asarray(img, dtype='float32')\n",
    "                data[i,j-1,:,:,:]=(arr.T-128)/128\n",
    "            else:\n",
    "                data[i,j-1,:,:,:]=data[i,j-2,:,:,:]\n",
    "            \n",
    "    return np.transpose(np.nan_to_num(data),(0,2,1,3,4)),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data,midlabel=load_data()\n",
    "nb_classes=20\n",
    "label = np_utils.to_categorical(midlabel-1, nb_classes)\n",
    "\n",
    "data1=data\n",
    "label1=label\n",
    "\n",
    "data2=np.transpose(data,(0,2,1,3,4))\n",
    "label2=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9, 3, 64, 48)\n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "def load_test_data():\n",
    "    data = np.empty((100,9,3,64,48),dtype=\"float32\")\n",
    "    label = np.empty((100,),dtype=\"uint8\")\n",
    "    imgPath='/Users/baidu/Documents/workspace/Action_recognition_scripts_UCF101/data/tmp_frames/test/'\n",
    "    f = open('/Users/baidu/Documents/workspace/Action_recognition_scripts_UCF101/data/ucfTrainTestlist/testlist01_100.txt')\n",
    "    vids = f.readlines()\n",
    "    vids = [video.rstrip() for video in vids]\n",
    "    \n",
    "    for i in range(len(vids)):\n",
    "        keypath=vids[i].split('/')[1].split('.')[0]\n",
    "        value=vids[i].split(' ')[1]\n",
    "        label[i]=value\n",
    "        #print keypath\n",
    "        #print value\n",
    "        for j in range(1,10):\n",
    "            path=imgPath+keypath+'_0'+str(j)+'.jpeg'\n",
    "            if os.path.exists(path):\n",
    "                img=Image.open(imgPath+keypath+'_0'+str(j)+'.jpeg')\n",
    "                img=img.resize((64,48))\n",
    "                #print imgPath+keypath+'_0'+str(j)+'.jpeg'\n",
    "                arr = np.asarray(img, dtype='float32')\n",
    "                data[i,j-1,:,:,:]=(arr.T-128)/128\n",
    "            else:\n",
    "                data[i,j-1,:,:,:]=data[i,j-2,:,:,:]\n",
    "            \n",
    "    return np.transpose(np.nan_to_num(data),(0,2,1,3,4)),label\n",
    "\n",
    "data_test,midlabel_test=load_test_data()\n",
    "label_test = np_utils.to_categorical(midlabel_test-1, nb_classes)\n",
    "data2_test=np.transpose(data_test,(0,2,1,3,4))\n",
    "label2_test=label_test\n",
    "print data2_test.shape\n",
    "print label2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2587 samples, validate on 100 samples\n",
      "Epoch 1/20\n",
      " 832/2587 [========>.....................] - ETA: 1491s - loss: 2.9933 - acc: 0.0781"
     ]
    }
   ],
   "source": [
    "#一种策略是使用TimeDistributed包裹2D卷积 参考：https://github.com/fchollet/keras/issues/2646\n",
    "model2 = Sequential()\n",
    "model2.add(TimeDistributed(Convolution2D(128, 3, 3,border_mode='valid'),input_shape=(9, 3, 64, 48)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(TimeDistributed(Convolution2D(64, 3, 3, \n",
    "                                         border_mode='valid',\n",
    "                                         W_regularizer=l2(0.01),\n",
    "                                         activity_regularizer=activity_l2(0.01))))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(TimeDistributed(Convolution2D(128, 3, 3, \n",
    "                                         border_mode='valid',\n",
    "                                         W_regularizer=l2(0.01),\n",
    "                                         activity_regularizer=activity_l2(0.01))))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(TimeDistributed(Flatten()))\n",
    "model2.add(TimeDistributed(Dense(256,activation='relu',\n",
    "                                 W_regularizer=l2(0.01),activity_regularizer=activity_l2(0.01))))\n",
    "model2.add(TimeDistributed(Dense(128,activation='relu',\n",
    "                                 W_regularizer=l2(0.01),activity_regularizer=activity_l2(0.01))))\n",
    "\n",
    "model2.add(LSTM(output_dim=256,return_sequences=True))\n",
    "model2.add(LSTM(output_dim=128))\n",
    "model2.add(Dense(20,activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(data2, label2,\n",
    "              batch_size=64,\n",
    "              nb_epoch=20,shuffle=True,validation_data=(data2_test, label2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#一种策略是完全使用3D卷积\n",
    "model = Sequential()\n",
    "# 1st layer group\n",
    "model.add(Convolution3D(16, 3, 3, 3, activation='relu',\n",
    "                        border_mode='same', name='conv1',\n",
    "                        input_shape=(3, 9, 64, 48)))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                        border_mode='valid', name='pool1'))\n",
    "#model.add(LSTM(64))\n",
    "#model.add(Dense(1))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, init='normal', activation='relu'))\n",
    "model.add(Dense(2, init='normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data1, label1,\n",
    "              batch_size=2,\n",
    "              nb_epoch=2,\n",
    "              shuffle=True,\n",
    "         ,validation_data=(data2_test, label2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s     \n",
      "[1.9148659229278564, 0.38]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model2.evaluate(data2_test, label2_test, verbose=1)\n",
    "print score\n",
    "model2.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c3d_model = Sequential()\n",
    "    # 1st layer group\n",
    "c3d_model.add(Convolution3D(64, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv1',\n",
    "                            subsample=(1, 1, 1),\n",
    "                            input_shape=(3, 16, 112, 112)))\n",
    "c3d_model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           border_mode='valid', name='pool1'))\n",
    "\n",
    "    # 2nd layer group\n",
    "c3d_model.add(Convolution3D(128, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv2',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           border_mode='valid', name='pool2'))\n",
    "\n",
    "    # 3rd layer group\n",
    "c3d_model.add(Convolution3D(256, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv3a',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(Convolution3D(256, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv3b',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           border_mode='valid', name='pool3'))\n",
    "\n",
    "    # 4th layer group\n",
    "c3d_model.add(Convolution3D(512, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv4a',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(Convolution3D(512, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv4b',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           border_mode='valid', name='pool4'))\n",
    "\n",
    "    # 5th layer group\n",
    "c3d_model.add(Convolution3D(512, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv5a',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(Convolution3D(512, 3, 3, 3, activation='relu',\n",
    "                            border_mode='same', name='conv5b',\n",
    "                            subsample=(1, 1, 1)))\n",
    "c3d_model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "c3d_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           border_mode='valid', name='pool5'))\n",
    "c3d_model.add(Flatten())\n",
    "\n",
    "    # FC layers group\n",
    "c3d_model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "c3d_model.add(Dropout(.5))\n",
    "c3d_model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "c3d_model.add(Dropout(.5))\n",
    "c3d_model.add(Dense(487, activation='softmax', name='fc8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @fchollet提供的一种解决方案\n",
    "参考：https://github.com/fchollet/keras/issues/129\n",
    "Put all the pictures in a sequence in a single batch\n",
    "insert the following custom layer after your convolution + flatten stage:\n",
    "class MyReshape(Layer):\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        nshape = (1,) + X.shape \n",
    "        return theano.tensor.reshape(X, nshape)\n",
    "It turns a batch of N vectors into a batch of size 1 containing a sequence of N vectors.\n",
    "\n",
    "Note that if you do something like that, the length of the input and of the labels won't match, so you won't be able to use the model.fit() method for training. However, you should be able to use the model.train(X, y) method just fine, on small minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
